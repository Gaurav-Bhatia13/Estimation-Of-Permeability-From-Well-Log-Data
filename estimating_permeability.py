# -*- coding: utf-8 -*-
"""Estimating Permeability

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SBsUeq4LJFiz3ha9JRbly-1PCNoMpe0G

# ESTIMATING PERMEABILITY FROM WIRELINE DATA
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_excel('/content/BTP dataset (1).xlsx')

df.head()

df.count()

j=0;
for i in df["KLOGH"]:
  j=j+1
  if(i>7000):
    print(j)

df["KLOGH"][0:20]

plt.figure(figsize=(4,3))
sns.distplot(x=df["KLOGH"][0:42000],color="Orange",kde=True,rug=True);
plt.show()

"""# ANALYZING HISTOGRAMS """

sns.histplot(x=df["KLOGH"],y=df["PHIF"],color="red")

sns.jointplot(x=df["KLOGH"],y=df["SW"],color="red")

sns.jointplot(x=df["KLOGH"],y=df["BVW"],color="red")

sns.jointplot(x=df["KLOGH"],y=df["VSH"],color="red")

sns.jointplot(x=df["KLOGH"],y=df["DEPTH"],color="red")

sns.jointplot(x=df["KLOGH"],y=df["VCARB"],color="red")

"""#

#APPLYING MACHINE LEARNING MODELS
"""

y= df["KLOGH"][0:]

y.head()
y.count()

x=df.drop('KLOGH', axis=1)

x.count()

x=x.drop('VCARB',axis=1)

x.head()

"""#finding missing values"""

#finding missing values
j=0
for i in x["BVW"]:
  if i>=0:
    pass
    
  else:
    
    print(j)
  j=j+1

"""#SUPPORT VECTOR MACHINE"""

from sklearn.svm import SVR
from sklearn.preprocessing import RobustScaler
rbX = RobustScaler()
# splitting the data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)
X = rbX.fit_transform(x_train)

rbY = RobustScaler()
Y = rbY.fit_transform(y_train)
svm = SVR()
svm.fit(X,Y)
svm_pred = svm.predict(rbX.transform(predict))
# splitting the data
# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)
# svm= SVR()
# svm.fit(x_train,y_train)
# y_predition=svm.predict(x_test)
# y_prediction

"""#MULTIPLE LINEAR REGRESSION
#y = β0 + β1X1 + β2X2 + β3X3 + .... + βpXp
"""

# importing train_test_split from sklearn
from sklearn.model_selection import train_test_split
# splitting the data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)


# importing module
from sklearn.linear_model import LinearRegression
# creating an object of LinearRegression class
LR = LinearRegression()
# fitting the training data
LR.fit(x_train,y_train)


y_prediction =  LR.predict(x_test)
y_prediction

sns.jointplot(x=y_test,y=y_prediction,color="red")

y_test.head()

import sklearn

from sklearn import metrics

"""#ERRORS"""

# calculate MAE, MSE, RMSE
print(metrics.mean_absolute_error(y_test, y_prediction))
print(metrics.mean_squared_error(y_test, y_prediction))
print(np.sqrt(metrics.mean_squared_error(y_test, y_prediction)))

"""#We cannot calculate accuracy for a regression model.
#performance of a regression model must be reported as an error

#DESICION TREE
"""

#DESICION TREE

# import the regressor
from sklearn.tree import DecisionTreeRegressor

# create a regressor object
regressor = DecisionTreeRegressor(random_state = 0)

# fit the regressor with X and Y data
regressor.fit(x_train, y_train)

y_prediction =  regressor.predict(x_test)
y_prediction


# calculate MAE, MSE, RMSE
print(metrics.mean_absolute_error(y_test, y_prediction))
print(metrics.mean_squared_error(y_test, y_prediction))
print(np.sqrt(metrics.mean_squared_error(y_test, y_prediction)))

sns.jointplot(x=y_test,y=y_prediction,color="red")

"""#APPLYING RANDOM FOREST """

#APPLYING RANDOM FOREST 


# Fitting Random Forest Regression to the dataset
# import the regressor
from sklearn.ensemble import RandomForestRegressor

# create regressor object
regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)

# fit the regressor with x and y data
regressor.fit(x_train, y_train)


y_prediction =  regressor.predict(x_test)


y_prediction
# calculate MAE, MSE, RMSE
print(metrics.mean_absolute_error(y_test, y_prediction))
print(metrics.mean_squared_error(y_test, y_prediction))
print(np.sqrt(metrics.mean_squared_error(y_test, y_prediction)))

sns.jointplot(x=y_test,y=y_prediction,color="red")

"""#Applying aritificial neural networks

"""

#Forward Propogation
# Let Y = WiIi = W1I1+W2I2+W3I3 
#where Y is KLOGH

#Back Propagation 
#Calculate the error i.e the difference between the actual output and the expected output. 
#Depending on the error, adjust the weights by multiplying the error with the input and again with the gradient of the Sigmoid curve:

import tensorflow as tf


ann=tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=6,activation='relu'))
ann.add(tf.keras.layers.Dense(units=6,activation='relu'))
ann.add(tf.keras.layers.Dense(units=1))
#training the ann
ann.compile(optimizer='adam',loss='mean_squared_error')
ann.fit(x_train,y_train,batch_size=32,epochs=1000)

y_prediction=ann.predict()

y_prediction[5000]

import math
rmse=math.sqrt(32568.4199)
rmse

"""#FUTURE PLAN - TO APPLY PNN APPROACH """